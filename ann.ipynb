{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2025ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "813a1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "                   sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e3872ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
       "0               7.0              0.27         0.36  ...       0.45      8.8        6\n",
       "1               6.3              0.30         0.34  ...       0.49      9.5        6\n",
       "2               8.1              0.28         0.40  ...       0.44     10.1        6\n",
       "3               7.2              0.23         0.32  ...       0.40      9.9        6\n",
       "4               7.2              0.23         0.32  ...       0.40      9.9        6\n",
       "...             ...               ...          ...  ...        ...      ...      ...\n",
       "4893            6.2              0.21         0.29  ...       0.50     11.2        6\n",
       "4894            6.6              0.32         0.36  ...       0.46      9.6        5\n",
       "4895            6.5              0.24         0.19  ...       0.46      9.4        6\n",
       "4896            5.5              0.29         0.30  ...       0.38     12.8        7\n",
       "4897            6.0              0.21         0.38  ...       0.32     11.8        6\n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c76f216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split into train, val, test\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.25, random_state=42)\n",
    "train_x = train.drop(['quality'], axis = 1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "test_x = test.drop(['quality'], axis = 1).values\n",
    "test_y = test[['quality']].values.ravel()\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63a658",
   "metadata": {},
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb8f66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## Define model architecture\n",
    "    mean=np.mean(train_x,axis=0)\n",
    "    var=np.var(train_x,axis=0)\n",
    "\n",
    "    model=keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean,variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## compile the model\n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "        learning_rate=params[\"lr\"],momentum=params[\"momentum\"]\n",
    "    ),\n",
    "    loss=\"mean_squared_error\",\n",
    "    metrics=[keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params wwith MLFLOW tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=64)\n",
    "        \n",
    "        ## Evaluate the model\n",
    "        eval_result=model.evaluate(valid_x,valid_y,batch_size=64)\n",
    "\n",
    "        eval_rmse=eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"eval_rmse\",eval_rmse)\n",
    "\n",
    "        ## log the model\n",
    "\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62154acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    # MLflow will track the parameters and results for each run\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x=train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_x=test_x,\n",
    "        test_y=test_y,\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "890d6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\":hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "630ed7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 1s/step - loss: 37.5346 - root_mean_squared_error: 6.1266\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 28.5936 - root_mean_squared_error: 5.3293 \n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1132 - root_mean_squared_error: 4.6401\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 17.7430 - root_mean_squared_error: 4.1042\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 16.1962 - root_mean_squared_error: 3.8985\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 16.0031 - root_mean_squared_error: 3.8723 - val_loss: 0.5734 - val_root_mean_squared_error: 0.7572\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.5977 - root_mean_squared_error: 0.7731\n",
      "\u001b[1m14/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6117 - root_mean_squared_error: 0.7820 \n",
      "\u001b[1m26/46\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6046 - root_mean_squared_error: 0.7775\n",
      "\u001b[1m40/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6008 - root_mean_squared_error: 0.7751\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5984 - root_mean_squared_error: 0.7735 - val_loss: 0.5650 - val_root_mean_squared_error: 0.7517\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6431 - root_mean_squared_error: 0.8019\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5798 - root_mean_squared_error: 0.7614 \n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5815 - root_mean_squared_error: 0.7625\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5785 - root_mean_squared_error: 0.7606\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.5784 - root_mean_squared_error: 0.7605 - val_loss: 0.5701 - val_root_mean_squared_error: 0.7551\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4879 - root_mean_squared_error: 0.6985\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5408 - root_mean_squared_error: 0.7350 \n",
      "\n",
      "  0%|          | 0/4 [00:02<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/04 01:18:52 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 200ms/step - loss: 34.1423 - root_mean_squared_error: 5.8431\n",
      "\u001b[1m13/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.3536 - root_mean_squared_error: 5.8611  \n",
      "\u001b[1m28/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.5953 - root_mean_squared_error: 5.8817\n",
      "\u001b[1m43/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.7465 - root_mean_squared_error: 5.8945\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 34.7925 - root_mean_squared_error: 5.8984 - val_loss: 35.6671 - val_root_mean_squared_error: 5.9722\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 34.8056 - root_mean_squared_error: 5.8996\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 34.6857 - root_mean_squared_error: 5.8894 \n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.8307 - root_mean_squared_error: 5.9017\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.9387 - root_mean_squared_error: 5.9108\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.9408 - root_mean_squared_error: 5.9110 - val_loss: 35.3999 - val_root_mean_squared_error: 5.9498\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 35.2057 - root_mean_squared_error: 5.9334\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.5134 - root_mean_squared_error: 5.8748 \n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.6308 - root_mean_squared_error: 5.8848\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.6756 - root_mean_squared_error: 5.8886\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 34.6778 - root_mean_squared_error: 5.8888 - val_loss: 35.1352 - val_root_mean_squared_error: 5.9275\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 35.0366 - root_mean_squared_error: 5.9192\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 34.8706 - root_mean_squared_error: 5.9051\n",
      "\n",
      " 25%|██▌       | 1/4 [00:10<00:29,  9.91s/trial, best loss: 0.7550686001777649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/04 01:19:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 225ms/step - loss: 36.2615 - root_mean_squared_error: 6.0218\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 35.5855 - root_mean_squared_error: 5.9645   \n",
      "\u001b[1m25/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.4727 - root_mean_squared_error: 5.7820\n",
      "\u001b[1m38/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4515 - root_mean_squared_error: 5.5997\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.2553 - root_mean_squared_error: 5.4879\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 30.1138 - root_mean_squared_error: 5.4745 - val_loss: 11.1521 - val_root_mean_squared_error: 3.3395\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 11.2269 - root_mean_squared_error: 3.3507\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4261 - root_mean_squared_error: 3.0671  \n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.2874 - root_mean_squared_error: 2.8689\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.3704 - root_mean_squared_error: 2.6960\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 7.3183 - root_mean_squared_error: 2.6858 - val_loss: 1.5230 - val_root_mean_squared_error: 1.2341\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.5519 - root_mean_squared_error: 1.2457\n",
      "\u001b[1m16/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3723 - root_mean_squared_error: 1.1706 \n",
      "\u001b[1m31/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.2626 - root_mean_squared_error: 1.1219\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1801 - root_mean_squared_error: 1.0837\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1756 - root_mean_squared_error: 1.0816 - val_loss: 0.6750 - val_root_mean_squared_error: 0.8216\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.6857 - root_mean_squared_error: 0.8281\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6509 - root_mean_squared_error: 0.8066 \n",
      "\n",
      " 50%|█████     | 2/4 [00:16<00:15,  7.52s/trial, best loss: 0.7550686001777649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/04 01:19:06 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 224ms/step - loss: 39.1375 - root_mean_squared_error: 6.2560\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.1151 - root_mean_squared_error: 6.0090   \n",
      "\u001b[1m30/46\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.6179 - root_mean_squared_error: 5.9676\n",
      "\u001b[1m44/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 35.3417 - root_mean_squared_error: 5.9445\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 35.2923 - root_mean_squared_error: 5.9403 - val_loss: 33.9864 - val_root_mean_squared_error: 5.8298\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 32.6356 - root_mean_squared_error: 5.7128\n",
      "\u001b[1m12/46\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.6340 - root_mean_squared_error: 5.7994 \n",
      "\u001b[1m24/46\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.6249 - root_mean_squared_error: 5.7986\n",
      "\u001b[1m34/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.5450 - root_mean_squared_error: 5.7918\n",
      "\u001b[1m42/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 33.4395 - root_mean_squared_error: 5.7826\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 33.3808 - root_mean_squared_error: 5.7775 - val_loss: 32.2732 - val_root_mean_squared_error: 5.6810\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 29.9606 - root_mean_squared_error: 5.4736\n",
      "\u001b[1m15/46\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4919 - root_mean_squared_error: 5.6116 \n",
      "\u001b[1m29/46\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4941 - root_mean_squared_error: 5.6119\n",
      "\u001b[1m39/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 31.4584 - root_mean_squared_error: 5.6087\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 31.4235 - root_mean_squared_error: 5.6056 - val_loss: 30.6412 - val_root_mean_squared_error: 5.5354\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 30.1629 - root_mean_squared_error: 5.4921\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 30.3612 - root_mean_squared_error: 5.5101 \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 30.3827 - root_mean_squared_error: 5.5120\n",
      "\n",
      " 75%|███████▌  | 3/4 [00:23<00:06,  6.82s/trial, best loss: 0.7550686001777649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/04 01:19:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:27<00:00,  6.97s/trial, best loss: 0.7550686001777649]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/04 01:19:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters: {'lr': np.float64(0.010425865500899478), 'momentum': np.float64(0.1648964198774655)}\n",
      "Best eval rmse: 0.7550686001777649\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # Conduct the hyperparameter search using Hyperopt\n",
    "    trials=Trials()\n",
    "    best=fmin(\n",
    "        fn=objective,\n",
    "        space=space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key=lambda x: x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53317e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
